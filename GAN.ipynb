{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network to generate images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bunch of imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th') # ensure our dimension notation matches\n",
    "import numpy as np\n",
    "import time\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D,Convolution2D, Conv2DTranspose, UpSampling2D, MaxPool2D\n",
    "from keras.layers import LeakyReLU, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as pplot\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The generator method\n",
    "the method generates images from random data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenerator():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The discriminator method\n",
    "the method predicts whether input image is real or fake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiscriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(\n",
    "                        64, 5, 5,\n",
    "                        border_mode='same',\n",
    "                        input_shape=(1, 28, 28)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(128, 5, 5))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdversarial(generator, discriminator):    \n",
    "    \n",
    "    AM = Sequential()\n",
    "    AM.add(generator)\n",
    "    discriminator.trainable = False;\n",
    "    AM.add(discriminator)\n",
    "    return AM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image utility methods \n",
    "combine_image is used to merge images into one image for display purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image\n",
    "\n",
    "def SaveImage(image,fileName):\n",
    "     image = image*127.5+127.5\n",
    "     pplot.imshow(Image.fromarray(image.astype(np.uint8)))\n",
    "     Image.fromarray(image.astype(np.uint8)).save(fileName+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train method.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator,adversarial, epochs=100,batch_size=1000):\n",
    "    \n",
    "    save_interval = 0\n",
    "    k = 1       # as in the GAN paper\n",
    "    \n",
    "    noise_input = None\n",
    "    if save_interval>0:\n",
    "        noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "    for e in range(epochs):     # epochs\n",
    "        for indBatch in range(int(x_train.shape[0]/batch_size)):\n",
    "            for j in range(0,k):        # loop for trianing of the discriminator\n",
    "                #images_train = x_train[np.random.randint(0,x_train.shape[0], size=batch_size), :, :, :]\n",
    "                images_train = x_train[indBatch*batch_size:(indBatch+1)*batch_size, :, :, :]\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "                images_fake = generator.predict(noise)\n",
    "                if indBatch % 20 == 0:\n",
    "                    image = combine_images(images_fake)\n",
    "                    image = image*127.5+127.5\n",
    "                    Image.fromarray(image.astype(np.uint8)).save(\n",
    "                            \"imagesGAN01\\\\\"+str(e)+\"_\"+str(indBatch)+\".png\")\n",
    "                x = np.concatenate((images_train, images_fake))\n",
    "                y = np.ones([2*batch_size, 1])\n",
    "                y[batch_size:, :] = 0\n",
    "                discriminator.trainable = True;\n",
    "                d_loss = discriminator.train_on_batch(x, y)\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100]) # sample minibatch of noise\n",
    "            discriminator.trainable = False;\n",
    "            a_loss = adversarial.train_on_batch(noise, y)\n",
    "            discriminator.trainable = True;\n",
    "            \n",
    "            log_mesg = \"e = %d: %d [D loss: %f, acc: %f]\" % (e, indBatch ,d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            \n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (e+1)%save_interval==0:\n",
    "                    plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(e+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we are prepared now. lets start the main task now... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "batch_size = 1000\n",
    "\n",
    "#x_train = input_data.read_data_sets(\"mnist\",\\\n",
    "#                one_hot=True).train.images\n",
    "#x_train = x_train.reshape(-1, img_rows,\\\n",
    "#                img_cols, 1).astype(np.float32)\n",
    "#x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "x_train = x_train.reshape((x_train.shape[0], 1) + x_train.shape[1:])\n",
    "\n",
    "\n",
    "generator = getGenerator()\n",
    "discriminator = getDiscriminator()\n",
    "adversarial = getAdversarial(generator,discriminator)\n",
    "\n",
    "adversarial.summary()\n",
    "d_optimiser = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "g_optimiser = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "\n",
    "#optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "generator.compile(loss='binary_crossentropy',optimizer = \"SGD\",metrics=['accuracy'])\n",
    "adversarial.compile(loss='binary_crossentropy',optimizer = g_optimiser,metrics=['accuracy'])\n",
    "discriminator.trainable = True;\n",
    "discriminator.compile(loss='binary_crossentropy',optimizer = d_optimiser,metrics=['accuracy'])\n",
    "\n",
    "train(generator, discriminator,adversarial)\n",
    "\n",
    "#AM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "images_fake = generator.predict(noise)\n",
    "#\n",
    "for i in range(images_fake.shape[0]):\n",
    "    pplot.subplot(4, 4, i+1)\n",
    "    image = images_fake[i, :, :, :]\n",
    "    image = np.reshape(image, [img_rows, img_cols])\n",
    "    pplot.imshow(image, cmap='gray')\n",
    "    pplot.axis('off')\n",
    "pplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
